{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛背景\n",
    "\n",
    "第三届中国AI+创新创业大赛由中国人工智能学会主办，半监督学习目标定位竞赛分赛道要求选手基于少量有标注数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。\n",
    "\n",
    "中国人工智能学会（Chinese Association for Artificial Intelligence，CAAI）成立于1981年，是经国家民政部正式注册的我国智能科学技术领域唯一的国家级学会，是全国性4A级社会组织，挂靠单位为北京邮电大学；是中国科学技术协会的正式团体会员，具有推荐“两院院士”的资格。\n",
    "\n",
    "中国人工智能学会目前拥有51个分支机构，包括43个专业委员会和8个工作委员会，覆盖了智能科学与技术领域。学会活动的学术领域是智能科学技术，活动地域是中华人民共和国全境，基本任务是团结全国智能科学技术工作者和积极分子通过学术研究、国内外学术交流、科学普及、学术教育、科技会展、学术出版、人才推荐、学术评价、学术咨询、技术评审与奖励等活动促进我国智能科学技术的发展，为国家的经济发展、社会进步、文明提升、安全保障提供智能化的科学技术服务。\n",
    "\n",
    "中国“AI+”创新创业大赛由中国人工智能学会发起主办，是为了配合实施创新驱动助力工程，深入开展服务企业技术创新活动，进一步提高我国文化建设和实践创新能力，展示智能科学与技术等相关学科建设的新经验、新成果，促进专业内涵的建设而发起的综合性大赛平台。\n",
    "\n",
    "飞桨PaddlePaddle作为中国首个自主研发、功能完备、开源开放的产业级深度学习平台，为本次比赛的参赛选手提供了集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体的一站式服务。百度大脑AI Studio作为官方指定且唯一的竞赛日常训练平台，为参赛选手提供高效的学习和开发环境，更有亿元Tesla V100算力免费赠送，助力选手取得优异成绩。\n",
    "\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简要介绍\n",
    "## 赛题背景\n",
    "半监督学习(Semi-Supervised Learning)是指通过大量无标记数据和少量有标记数据完成模型训练，解决具有挑战性的模式识别任务。近几年，随着计算硬件性能的提升和大量大规模标注数据集的开源，基于深度卷积神经网络(Deep Convolutional Neural Networks, DCNNs)的监督学习研究取得了革命性进步。然而，监督学习模型的优异性能要以大量标注数据作为支撑，可现实中获得数量可观的标注数据十分耗费人力物力(例如，获取像素级标注数据)。于是， 半监督学习逐渐成为深度学习领域的热门研究方向，只需要少量标记数据就可以完成模型训练过程，更适用于现实场景中的各种任务。\n",
    "## 比赛任务\n",
    "本次比赛要求选手基于少量有标签的数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。每- -位参赛选手仅可以使用ImageNet大型视觉识别竞赛(LSVRC)的训练集图像作为训练数据，其中有标签的训练数据仅可以使用大赛组委会提供的像素级标注。\n",
    "## 数据集介绍\n",
    "* 训练数据集包括50,000幅像素级标注的图像，共包含500个类，每个类100幅图像;\n",
    "* A榜测试数据集包括1 1,878幅无标注的图像;\n",
    "* B榜测试数据集包括10,989幅无标注的图像。\n",
    "## 评价指标\n",
    "**本次比赛使用loU曲线作为评价指标，即利用预测的目标的定位概率图，计算不同阈值下预测结果与真实目标之间的IoU分数，最后取一个最高点作为最终的分数**。在理想状态下，loU曲线最高值接近1.0,对应的阈值为255,因为阈值越高，目标对象与背景的对比度越高。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 团队\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/de6f243337de47149c30d6916de32bdaf5424eba57484a2fa5fd0da2f5f6fda3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 研究方向\n",
    "<font size=3 >本人（张牙舞爪）目前是研究生在读，研究方向为显著目标检测，所谓显著目标检测，即探测出图像中的显著物体，并用黑白图展示出来，如下图左边为自然场景，右边为ground truth (真值图）</font>\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a15d536d3cc54ab88e99e4d7b16aef4a756c079a32e348cf916b957dc22d3b02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3 > 因为此次比赛与我的研究发现十分相似，所以积极地地报名了这次比赛，十分有幸能在比赛中取得优秀的成绩，特别感谢队友的帮助。\n",
    "\n",
    " 另外第一次用markdown展示，写的太丑请见谅\n",
    "  \n",
    "  这次比赛的训练数据也与此相似，因此就不过多展示图片了\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛基础知识点与主流处理方法\n",
    "\n",
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在深度学习的图像处理大多基于全卷积神经网络（FCN）的架构，即使用卷积层获取图像特征信息，再通过卷积层融合不同层的特征信息后，将特征图通过反卷积或者上采样方式恢复到原尺度的大小，实现图片输入、图片输出的效果.\n",
    "FCN最早是语义分割领域提出来了，因为语义分割领域需要像素级别的输出，传统的CNN只能基于超像素进行预测，从而导致预测图存在边界模糊等问题. FCN的架构可以从下图看到\n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/bed37ff7c5824fc2bde6324f8b2ff180cb5d1dfcb4214556972673422cbcbe23)\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FCN是以encoder-decoder为架构进行图像预测的，encoder通常由在ImageNet数据集上预训练的模型构成，例如ResNet和VGG，通过去掉encoder的分类层（最后的池化与全连接层）形成特征提取网络，在encoder中，不同层的特征具有不同的尺寸和语义信息，\n",
    "  以ResNet为例，假如输入图像尺寸为3×256×256，则可以在ResNet系列模型中的conv、layer1、layer2、layer3、layer4中提取出64×160×160、256×80×80、512×40×40、1024×20×20、2048×10×10 一共五层特征信息，图像分类的下游任务一般都是以这些特征信息进行处理。\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;五层特征分别有着不同的作用，具有大尺寸的浅层特征有着丰富的细节信息，但同时存在更多的背景噪音\n",
    "小尺寸的深层特征具有高层语义信息，可以更好地定位物体的位置，但是过度的池化操作会导致图片信息丢失以及深层特征的粗糙边界，[点击这里可以看每层特征的展示图像](https://blog.csdn.net/u012435142/article/details/84711978)\n",
    "  \n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，具有丰富细节信息的浅层特征与可以定位目标的深层特征进行互补融合就是生成高质量预测图的关键，融合过程即为decoder.\n",
    " 所以比赛的思路就是先用encoder提取特征 -> 再通过decoder融合特征 -> 将融合后的特征使用卷积层调整为单通道 -> 经上采样恢复原尺寸后输出.\n",
    " 这也是大部分深度学习图像处理的流程。但是，如果在encoder之后，decoder之前对特征进行优化去杂，往往会产生更好的效果。所以该比赛的模型可以用以下的图来表述\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cf9b38ee9bbe42509e230e8c60c97f90db8fc7b9a3654589a1d8084eb0576202)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以我参加比赛的其中一个模型为例，展示一下图像处理流程，就像我们上面说的，先使用encoder（Backbone, 骨干网络，一般为ResNet及其衍生系列，最近Transformer也很厉害，我们也使用了Transformer作为骨干网络来构建模型)获取特征信息，然后通过特征处理模块（SSM，PMFG，这些模块主要起优化特征信息的作用，不做特别细致讲解为啥会优化特征，可等我论文出版后直接看论文，或者自己看代码领悟）优化特征信息，最后使用decoder聚合特征，接着一个卷积层将特征输出到符合要求的通道数以及上采样等操作后输出图像 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛细节\n",
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在比赛的过程中，我发现大多数参赛人员都是以Paddleseg为基础，在Paddleseg上进行修改。我们团队也是，但有一些细节需要注意。\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**本次比赛使用loU曲线作为评价指标，即利用预测的目标的定位概率图，计算不同阈值下预测结果与真实目标之间的IoU分数，最后取一个最高点作为最终的分数**\n",
    "\n",
    "这句话的意思就是在不同阈值下计算预测结果与真值图的iou，然后取iou最高的以及阈值作为最终分数。下面先通过iou公式了解一下这句话是什么意思\n",
    "$$IOU = \\frac{TP}{FP+TP+FN}$$\n",
    "[可以在这里了解什么是TP、FP、TN、FN](https://cloud.tencent.com/developer/article/1490456)\n",
    "\n",
    "往往来说，图像处理的输出为经过sigmoid激活函数处理后归一化到[0,1]之间的float32的小数。存为图像则需要再乘255。因此这次比赛的预测图是范围为[0, 255]的unit8类型的灰度图。\n",
    "然后根据[0, 255] 选择255个阈值来进行计算，大于阈值的设为正例，小于阈值的设为负例，从而计算iou分数，选择最高的iou分数作为成绩。\n",
    " 然而我在Paddleseg的训练文件里面发现Paddleseg处理后得到的图片的像素值要么是0， 要么是240+，这样会导致该预测结果在不同阈值下的分数几乎一样，且无法很好地得到很高的成绩，通常表现为结果中Peak Threshold值较高。因此，我们通过修改Paddleseg的源码，使其符合我们所说的那种要求，发现分数有很明显的提升 因为改动较多， 所以具体的详见 external-libraries/paddle_seg_semi1/paddleseg/core里面的四个py文件。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 第一名思路分享\n",
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们的模型处理流程就是根据上面提到的encoder-decoder + 特征处理。之前我们有提到，encoder往往采用ImageNet预训练的网络进行特征提取，也叫做骨干网络，因此骨干网络在ImageNet数据集表现越好，就越能提取到有用的特征信息，所以我们在[Pacclecls图像分类模型](https://github.com/PaddlePaddle/PaddleClas/blob/release/2.2/docs/zh_CN/ImageNet_models_cn.md)这里寻找效果好的骨干网络。最终我们选取了Res2Net200_vd_26w_4s_ssld、ResNeXt101_32x16d_wsl、SwinTransformer_large_patch4_window12_384三个模型，稍加修改后作为我们的骨干网络，有了骨干网络之后，我根据自己一年研究方向的学习，自己写了两个特征处理模块与解码器，并没有参照任何baseline或者paddleseg里面的模型，第一个网络叫Attention Guided Contextual Feature Fusion Network（ACFFNet),这一个网络（我的研究方向21年SOTA水平）是我在7月份投稿的一篇sci论文略微修改而来。第二个网络叫Feature Mutual Feedback Network（FNFNet），此为本人正在写的sci论文里的模型修改而来（21年SOTA水平）。\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 根据我们这三个骨干网络以及两种特征处理模块与解码器，我们构造了四个网络，即res2net200 + ACFFNet（单模型 榜A iou 0.80918）、res2net200 + FMFNet（单模型 榜A iou 0.80249）、ST + ACFFNet （提交次数有限，榜A、B未做单模型测试）、ResNext101 + ACFFNet（提交次数有限，榜A、B未做单模型测试）。用那么多ACFFNet是因为我对这个网络比较自信。\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;之所以构造4个模型，就是因为模型融合往往会在比赛里得到较好的成绩，因此我们使用四个模型的预测结果，加权后输出作为最终预测图。\n",
    " \n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面展示的图就是FMFNet的架构，下面展示ACFFNet的架构\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cb90f2f068914abdb4d09270ee895c1b4aeef69467824734a7d5bba353f2b589)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;各个小模块都详细画图解释了，具体每个模块有什么功效就不细讲了，都是用来优化特征信息的。看不懂的话可以在external-libraries/paddle_seg_semi1/paddleseg/models/ACFFNetwork.py 中看模型的代码，也可以等我论文出来后看论文。\n",
    " \n",
    "  **本次比赛项目的目录结构如下**</br>\n",
    " data:</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;-dataxxxxx:</br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; \t-dataset.zip #这个是压缩包的训练集，因为个人爱好把彩色图的文件夹修改为了image，标签图的文件夹修改为了mask</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -B榜测试数据集.zip</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; -ACFFViT4.pdparams  #模型权重</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;\t-NextACFF.pdparams #模型权重</br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; \t-res2net200_score_0.80918.pdparams #模型权重</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;\t-Res2Net200_vd_26w_4s_ssld_pretrained.pdparams #骨干网络权重，测试不用训练用</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;\t-200_FMF.pdparams #模型权重</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;\t-paddle-seg-semi1.zip # paddleseg开发包</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-image #dataset.zip 解压后产生</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-mask #dataset.zip 解压后产生</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-test_image #dataset.zip 解压后产生</br>\n",
    " \n",
    "运行完程序后会出现新的文件夹\n",
    "\n",
    " output:</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-result_fmf #res2net200+FMFNet 预测结果</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-logits #图片npy文件</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-pre  #图片</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-result_acff #res2net200+ACFFNet 预测结果</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-logits #图片npy文件</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-pre  #图片</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-result_vit #ST+ACFFNet 预测结果</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-logits #图片npy文件</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-pre  #图片</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-result_acffnext #resnext101+ACFFNet预测结果</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-logits #图片npy文件</br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-pre  #图片</br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;-result_ensem_weight #模型融合结果</br>\n",
    "   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-pre  #图片</br>\n",
    "   \n",
    "   \n",
    " 接下来我们会讲解使用paddleseg添加我们的模型后，训练以及预测的部分。</br>\n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛分数变化（大概）\n",
    "<font size=3 >因为赛时一个多月，另外比赛初期并没有过于重视分数，所以只能记得大概的模型变化以及分数变化（分数榜A和榜B从头到尾都是第一）\n",
    "A榜\n",
    "1.  刚开赛的时候，使用resnet50 + ACFFNet  得分为0.7左右\n",
    "2.  切换骨干网络，resnet152 + ACFFNet 得分为0.72左右\n",
    "3.  切换骨干网络，res2net152 + ACFFNet，，分数为0.78左右\n",
    "4.  损失函数由bce替换为加权bce（本人提出， 可在paddleseg里损失函数里看到semi_loss.py）和cel（MINet文章提出）提到0.804左右\n",
    "5.  找到队友\n",
    "6.  队友提出模型融合策略，因此我拿出第二个模型 res2net152 + FMFNet A榜分数0.801左右\n",
    "7.  一次提问中，GT哥提供了paddleclass分类模型的网址，找到了res2net200, 两个模型分别切换骨干网络，res2net200 + ACFFNet 最高得分0.80918， res2net200 + FMFNet 最高得分0.80249\n",
    "8.  队友提出了模型融合策略，并修改了paddleseg代码，将图片保存为float32的npy文件，在npy文件实现模型融合，得到的结果保存为灰度图，而不是paddleseg的黑白图，因此，融合了res2net152 + FMFNet 和 res2net200 + ACFFNet后  得分0.81+\n",
    "9.  融合 res2net200 + FMFNet 和 res2net200 + ACFFNet 得分0.8118\n",
    "10. 找到第三个骨干网络，SwinTransformer + ACFFNet，测试三模型融合，最终A榜得分0.81425\n",
    "  \n",
    "  \n",
    " B榜\n",
    "1. A榜最好的模型测试B榜数据集，得分0.80139\n",
    "2. 发现最后几次迭代效果不如中间迭代效果好后，重新训练res2net200 + FMFNet，损失函数切换为iou loss， 得分0.80355\n",
    "3. 使用ResNeXt101_32x16d_wsl作为骨干网络，训练第四个模型ResNeXt101 + ACFFNet，融合四个模型后，得分0.80383\n",
    "4. 想了很多自以为不错的模型融合策略，均以失败告终，分数都在0.80左右徘徊\n",
    "6. 最后尝试训练所有数据，只留20个作为验证集，后发现效果不行。原本固定随机种子，选取2k个作为验证集。\n",
    "5. 最后尝试加权融合，第一次尝试以[0.4, 0.2, 0.2, 0.2]的权重给四个模型 res2net200 + ACFFNet、res2net200 + FMFNet、ResNeXt101 + ACFFNet、SwinTransformer + ACFFNet，谁知第一次竟然是最好的成绩\n",
    " \n",
    "  最终得分0.80428\n",
    "  \n",
    " 另外有许多失败的尝试，已经记不太起来了，总之，分数的不断提升，是不断试错，不断纠正后的结果。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data99666\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 14.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!unzip -oq /home/aistudio/data/data99666/A_Pred.zip -d data/\r\n",
    "!unzip -oq /home/aistudio/data/data99666/dataset.zip -d /home/aistudio/data/\r\n",
    "#!unzip -oq /home/aistudio/data/data99666/paddle-seg-semi1.zip -d external-libraries\r\n",
    "\r\n",
    "# 注意，第一次运行若在external-libraries目录下没有paddle_seg-semi1的文件夹，请取消第三行的注释，然后会在external-libraries下面生成一个paddle-seg-semi1的文件，\r\n",
    "# 麻烦一下rename 成paddle_seg-semi1，这是paddleseg源码被我修改后的，我添加了自己的网络，损失函数等.\r\n",
    "# 再次注意，因为有用到data99666这个路径，但是每个人的不一样，所以接下来的这个路径还请麻烦每个人单独修改一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压B榜测试集\r\n",
    "!unzip -oq /home/aistudio/data/data99666/B榜测试数据集.zip -d /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "sys.path.append('/home/aistudio/external-libraries/paddle_seg_semi1') # 我额外加的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3 >&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本次比赛，我们队伍一共使用了4个模型，通过四个模型的加权融合后得出最好的结果，下面分别介绍每个模型。这些都是基于paddleseg套件进行修改的，所以按照paddleseg的方法就行模型训练和预测\n",
    "  \n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与其说是四个模型，不如说是3种骨干网络，2种解码网络\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3 >四个模型的模型文件可在  \n",
    "\n",
    "external-libraries/paddle_seg_semi1/paddleseg/models/FMFNetwork.py\n",
    "\n",
    "external-libraries/paddle_seg_semi1/paddleseg/models/ACFFNetwork.py\n",
    "\n",
    "external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py\n",
    "\n",
    "external-libraries/paddle_seg_semi1/paddleseg/models/Next_ACFF.py\n",
    "\n",
    "看到\n",
    "\n",
    "四个配置文件可在external-libraries/paddle_seg_semi1/configs/semi 看到\n",
    "\n",
    "分别叫 fcn_FMF_semi_50k.yml、fcn_ACFFNet_semi_50k.yml、 fcn_ACFFViT.yml、 fcn_NextACFF.yml \n",
    "\n",
    "数据处理没啥可看的 可在external-libraries/paddle_seg_semi1/paddleseg/datasets/semi.py 看到\n",
    "\n",
    "**另外，严正声明，比赛所用的模型，除骨干网络外，皆为本人所提出的模型算法，其中ACFFNetwork.py中除骨干网络外的模型为本人所投sci（在大修）文章中的模型稍加修改后的模型， FMFNet中除骨干网络外的模型为本人正在写sci的模型修改后的模型，\n",
    "与baseline几乎无相似点，另外本人及本团队严格遵守了比赛规则，不存在犯规情况。**\n",
    "\n",
    "**另外，本人十分愿意为paddleseg提供比赛上述两个模型**\n",
    " \n",
    "  PS：将最后一个卷积层的输出通道改为N，就是N分类语义分割模型.搭配语义分割的损失函数以及数据就可以做语义分割任务了，有这方面想法的同学可以尝试一下。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下面详解每个模型的训练与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################### FMF ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'external-libraries/paddle_seg_semi1/'\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "2021-08-06 21:13:22 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-08-06 21:13:23 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 32\n",
      "iters: 36000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0001\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: SemiLoss\n",
      "model:\n",
      "  backbone:\n",
      "    pretrained: /home/aistudio/data/data99666/Res2Net200_vd_26w_4s_ssld_pretrained.pdparams\n",
      "    type: Res2Net\n",
      "  num_classes: 2\n",
      "  type: FMFModel\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.5\n",
      "    contrast_range: 0.5\n",
      "    saturation_range: 0.5\n",
      "    type: RandomDistort\n",
      "  - type: RandomBlur\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "------------------------------------------------\n",
      "W0806 21:13:24.162475  1249 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0806 21:13:24.162539  1249 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-08-06 21:13:29 [INFO]\tLoading pretrained model from /home/aistudio/data/data99666/Res2Net200_vd_26w_4s_ssld_pretrained.pdparams\n",
      "2021-08-06 21:13:33 [INFO]\tThere are 1685/1685 variables loaded into Res2Net.\n",
      "init finished!\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "2021-08-06 21:14:58 [INFO]\t[TRAIN] epoch=1, iter=100/36000, loss=0.7788, lr=0.009975, batch_cost=0.8476, reader_cost=0.00737, ips=37.7532 samples/sec | ETA 08:27:09\n",
      "2021-08-06 21:16:22 [INFO]\t[TRAIN] epoch=1, iter=200/36000, loss=0.7425, lr=0.009951, batch_cost=0.8368, reader_cost=0.00015, ips=38.2389 samples/sec | ETA 08:19:19\n",
      "2021-08-06 21:17:46 [INFO]\t[TRAIN] epoch=1, iter=300/36000, loss=0.6685, lr=0.009926, batch_cost=0.8431, reader_cost=0.00027, ips=37.9557 samples/sec | ETA 08:21:38\n",
      "2021-08-06 21:19:10 [INFO]\t[TRAIN] epoch=1, iter=400/36000, loss=0.6016, lr=0.009901, batch_cost=0.8415, reader_cost=0.00016, ips=38.0293 samples/sec | ETA 08:19:15\n",
      "2021-08-06 21:20:36 [INFO]\t[TRAIN] epoch=1, iter=500/36000, loss=0.5719, lr=0.009876, batch_cost=0.8536, reader_cost=0.00023, ips=37.4889 samples/sec | ETA 08:25:02\n",
      "2021-08-06 21:22:01 [INFO]\t[TRAIN] epoch=1, iter=600/36000, loss=0.5579, lr=0.009852, batch_cost=0.8512, reader_cost=0.00015, ips=37.5962 samples/sec | ETA 08:22:10\n",
      "2021-08-06 21:23:27 [INFO]\t[TRAIN] epoch=1, iter=700/36000, loss=0.5381, lr=0.009827, batch_cost=0.8604, reader_cost=0.00017, ips=37.1902 samples/sec | ETA 08:26:13\n",
      "2021-08-06 21:24:52 [INFO]\t[TRAIN] epoch=1, iter=800/36000, loss=0.5270, lr=0.009802, batch_cost=0.8465, reader_cost=0.00017, ips=37.8008 samples/sec | ETA 08:16:38\n",
      "2021-08-06 21:26:16 [INFO]\t[TRAIN] epoch=1, iter=900/36000, loss=0.5277, lr=0.009777, batch_cost=0.8424, reader_cost=0.00016, ips=37.9853 samples/sec | ETA 08:12:49\n",
      "2021-08-06 21:27:41 [INFO]\t[TRAIN] epoch=1, iter=1000/36000, loss=0.5240, lr=0.009752, batch_cost=0.8517, reader_cost=0.00017, ips=37.5711 samples/sec | ETA 08:16:50\n",
      "2021-08-06 21:29:06 [INFO]\t[TRAIN] epoch=1, iter=1100/36000, loss=0.5138, lr=0.009728, batch_cost=0.8496, reader_cost=0.00017, ips=37.6644 samples/sec | ETA 08:14:11\n",
      "2021-08-06 21:30:31 [INFO]\t[TRAIN] epoch=1, iter=1200/36000, loss=0.5077, lr=0.009703, batch_cost=0.8544, reader_cost=0.00016, ips=37.4541 samples/sec | ETA 08:15:32\n",
      "2021-08-06 21:31:56 [INFO]\t[TRAIN] epoch=1, iter=1300/36000, loss=0.5093, lr=0.009678, batch_cost=0.8479, reader_cost=0.00015, ips=37.7393 samples/sec | ETA 08:10:22\n",
      "2021-08-06 21:33:20 [INFO]\t[TRAIN] epoch=1, iter=1400/36000, loss=0.4995, lr=0.009653, batch_cost=0.8388, reader_cost=0.00015, ips=38.1516 samples/sec | ETA 08:03:41\n",
      "2021-08-06 21:34:44 [INFO]\t[TRAIN] epoch=1, iter=1500/36000, loss=0.5041, lr=0.009628, batch_cost=0.8425, reader_cost=0.00015, ips=37.9835 samples/sec | ETA 08:04:25\n",
      "2021-08-06 21:36:09 [INFO]\t[TRAIN] epoch=2, iter=1600/36000, loss=0.4992, lr=0.009603, batch_cost=0.8450, reader_cost=0.00591, ips=37.8698 samples/sec | ETA 08:04:28\n",
      "2021-08-06 21:37:35 [INFO]\t[TRAIN] epoch=2, iter=1700/36000, loss=0.4903, lr=0.009578, batch_cost=0.8621, reader_cost=0.00021, ips=37.1189 samples/sec | ETA 08:12:49\n",
      "2021-08-06 21:39:00 [INFO]\t[TRAIN] epoch=2, iter=1800/36000, loss=0.4868, lr=0.009554, batch_cost=0.8505, reader_cost=0.00018, ips=37.6250 samples/sec | ETA 08:04:47\n",
      "2021-08-06 21:40:25 [INFO]\t[TRAIN] epoch=2, iter=1900/36000, loss=0.4898, lr=0.009529, batch_cost=0.8444, reader_cost=0.00015, ips=37.8956 samples/sec | ETA 07:59:54\n",
      "2021-08-06 21:41:49 [INFO]\t[TRAIN] epoch=2, iter=2000/36000, loss=0.4846, lr=0.009504, batch_cost=0.8420, reader_cost=0.00016, ips=38.0043 samples/sec | ETA 07:57:08\n",
      "2021-08-06 21:41:49 [INFO]\tStart evaluating (total_samples=20, total_iters=20)...\n",
      "20/20 [==============================] - 4s 182ms/step - batch_cost: 0.1821 - reader cost: 7.5127e-0\n",
      "2021-08-06 21:41:52 [INFO]\t[EVAL] #Images=20 mIoU=0.1177 Acc=0.1177 Kappa=0.1177 \n",
      "2021-08-06 21:41:52 [INFO]\t[EVAL] Class IoU: \n",
      "0.1177\n",
      "2021-08-06 21:41:52 [INFO]\t[EVAL] Class Acc: \n",
      "0.1177\n",
      "2021-08-06 21:42:02 [INFO]\t[EVAL] The model with the best validation mIoU (0.1177) was saved at iter 2000.\n",
      "2021-08-06 21:43:26 [INFO]\t[TRAIN] epoch=2, iter=2100/36000, loss=0.4900, lr=0.009479, batch_cost=0.8449, reader_cost=0.00018, ips=37.8726 samples/sec | ETA 07:57:23\n",
      "2021-08-06 21:44:51 [INFO]\t[TRAIN] epoch=2, iter=2200/36000, loss=0.4814, lr=0.009454, batch_cost=0.8424, reader_cost=0.00014, ips=37.9856 samples/sec | ETA 07:54:33\n",
      "2021-08-06 21:46:15 [INFO]\t[TRAIN] epoch=2, iter=2300/36000, loss=0.4916, lr=0.009429, batch_cost=0.8464, reader_cost=0.00017, ips=37.8076 samples/sec | ETA 07:55:23\n",
      "2021-08-06 21:47:40 [INFO]\t[TRAIN] epoch=2, iter=2400/36000, loss=0.4786, lr=0.009404, batch_cost=0.8411, reader_cost=0.00015, ips=38.0432 samples/sec | ETA 07:51:02\n",
      "2021-08-06 21:49:03 [INFO]\t[TRAIN] epoch=2, iter=2500/36000, loss=0.4770, lr=0.009379, batch_cost=0.8399, reader_cost=0.00015, ips=38.0996 samples/sec | ETA 07:48:56\n",
      "2021-08-06 21:50:28 [INFO]\t[TRAIN] epoch=2, iter=2600/36000, loss=0.4763, lr=0.009354, batch_cost=0.8413, reader_cost=0.00015, ips=38.0363 samples/sec | ETA 07:48:19\n",
      "2021-08-06 21:51:52 [INFO]\t[TRAIN] epoch=2, iter=2700/36000, loss=0.4805, lr=0.009329, batch_cost=0.8428, reader_cost=0.00016, ips=37.9692 samples/sec | ETA 07:47:44\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 154, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 149, in main\n",
      "    keep_checkpoint_max=args.keep_checkpoint_max)\n",
      "  File \"/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/core/train.py\", line 203, in train\n",
      "    loss.backward()\n",
      "  File \"<decorator-gen-123>\", line 2, in backward\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 225, in __impl__\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\", line 236, in backward\n",
      "    framework._dygraph_tracer())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 这是我自己添加的第一个模型及其配置文件，模型的具体细节可以在 /home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/FMFNetwork.py 这个目录里看到\r\n",
    "# 简要介绍一下模型、损失函数、数据增强、学习率和训练策略以及出现的一些问题\r\n",
    "# 模型：我们采用FCN架构，以paddlecls中提供的res2net200以及其预训练权重做为骨干网络来提取特征信息，输入数据为3×256×256的图片，四层layer我们分别提取了256×64×64、\r\n",
    "     # 512×32×32 、 1024×16×16、 2048×8×8的特征信息\r\n",
    "     # 本次比赛的要求是生成具有目标的单通道图，一般的做法为四层特征信息的融合，即encoder-decoder架构，我们也是采用这样的方法，只不过在中间添加了特征优化的模块，可见 FMFNetwork.py中的语义补充模块（SSM），特征交互模块（FIM），\r\n",
    "     # 关于这俩模块我将会在另外的方案分享里具体描述，本次提交就不做过细讲解.四层特征经过融合后使用3×3卷积调整为1通道，经过sigmoid函数与上采样恢复到原尺寸输出后在loss函数（一会细讲）和Momentum优化器的优化下进行训练.\r\n",
    "# 损失函数：我们自己实现了iou损失函数在2分类中的实现 代码见：external-libraries/paddle_seg_semi1/paddleseg/models/losses/semi_loss.py\r\n",
    "# 数据增强：根据paddleseg的用法，我们并没有用过多的数据增强操作，只用了resize、 对比度亮度、水平翻转、垂直反转、随即模糊、归一化这些操作，训练数据使用随机种子固定随机数，随机选取2K个作为验证集.\r\n",
    "# 学习率：使用paddleseg推荐的poly decay 作为学习率衰减策略，初始学习率为0.01，最小学习率为0.0001，\r\n",
    "# 训练策略以及一些问题：训练策略如下，2000次迭代保存一次模型，本来打算训练2w4k次迭代，但是发现模型在1w2k次迭代效果最好，但是loss和评价指标却一直在变好，可能是存在验证集过拟合的现象，具体原因不知.\r\n",
    "\r\n",
    "# 这是训练代码，复现请配置好文件后直接运行下一个代码块 如果要训练 就取消15-21行的注释\r\n",
    "# 评价指标 从miou 被我修改为了mae \r\n",
    "\r\n",
    "# %cd external-libraries/paddle_seg_semi1/\r\n",
    "# !python train.py --config configs/semi/fcn_FMF_semi_50k.yml \\\r\n",
    "# --do_eval \\\r\n",
    "# --save_dir /home/aistudio/output/fmf \\\r\n",
    "# --save_interval 2000 \\\r\n",
    "# --log_iters 100  \\\r\n",
    "# --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'external-libraries/paddle_seg_semi1/'\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "2021-08-06 10:05:12 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 32\n",
      "iters: 36000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.0001\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: SemiLoss\n",
      "model:\n",
      "  backbone:\n",
      "    pretrained: /home/aistudio/data/data99666/Res2Net200_vd_26w_4s_ssld_pretrained.pdparams\n",
      "    type: Res2Net\n",
      "  num_classes: 2\n",
      "  type: FMFModel\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - max_rotation: 30\n",
      "    max_scale_factor: 1.5\n",
      "    min_scale_factor: 0.5\n",
      "    size:\n",
      "    - 256\n",
      "    - 256\n",
      "    translation_offset: 128\n",
      "    type: RandomAffine\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.5\n",
      "    contrast_range: 0.5\n",
      "    saturation_range: 0.5\n",
      "    type: RandomDistort\n",
      "  - type: RandomBlur\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "------------------------------------------------\n",
      "W0806 10:05:12.835805   871 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0806 10:05:12.835866   871 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "# 这是预测的代码，依然是根据paddleseg套件直接运行的，采取了多尺度预测和水平翻转的预测策略， 这里就没什么好讲的了，可以直接运行\r\n",
    "# 要复现结果，则必须运行这块代码\r\n",
    "%cd external-libraries/paddle_seg_semi1/\r\n",
    "!python predict.py --config configs/semi/fcn_FMF_semi_50k.yml \\\r\n",
    "--model_path /home/aistudio/data/data99666/200_FMF.pdparams \\\r\n",
    "--image_path /home/aistudio/data/test_image/ \\\r\n",
    "--save_dir /home/aistudio/output/result_fmf \\\r\n",
    "--aug_pred --scales  1 1.5 2 \\\r\n",
    "--flip_horizontal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############# ACFF ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/external-libraries/paddle_seg_semi1\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2021-07-29 21:51:18 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-166-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: False\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-07-29 21:51:35 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 32\n",
      "iters: 24000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0.001\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: SemiLoss\n",
      "model:\n",
      "  backbone:\n",
      "    layers: 200\n",
      "    pretrained: /home/aistudio/data/data99666/Res2Net200_vd_26w_4s_ssld_pretrained.pdparams\n",
      "    scales: 4\n",
      "    type: Res2Net\n",
      "    width: 26\n",
      "  num_classes: 2\n",
      "  type: ACFFModel\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 0.0005\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: train\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.5\n",
      "    contrast_range: 0.5\n",
      "    saturation_range: 0.5\n",
      "    type: RandomDistort\n",
      "  - type: RandomBlur\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/data\n",
      "  mode: val\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - mean:\n",
      "    - 0.485\n",
      "    - 0.456\n",
      "    - 0.406\n",
      "    std:\n",
      "    - 0.229\n",
      "    - 0.224\n",
      "    - 0.225\n",
      "    type: Normalize\n",
      "  type: SEMI\n",
      "------------------------------------------------\n",
      "2021-07-29 21:51:47 [INFO]\tLoading pretrained model from /home/aistudio/data/data99666/Res2Net200_vd_26w_4s_ssld_pretrained.pdparams\n",
      "2021-07-29 21:51:53 [INFO]\tThere are 1685/1685 variables loaded into Res2Net.\n",
      "init finished!\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 154, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 149, in main\n",
      "    keep_checkpoint_max=args.keep_checkpoint_max)\n",
      "  File \"/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/core/train.py\", line 194, in train\n",
      "    logits_list = model(images)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFFNetwork.py\", line 411, in forward\n",
      "    x1, x2, x3, x4, x5 = self.backbone(x)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/FMFNetwork.py\", line 423, in forward\n",
      "    y = self.pool2d_max(y)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\", line 898, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/pooling.py\", line 518, in forward\n",
      "    name=self.name)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/pooling.py\", line 720, in max_pool2d\n",
      "    'data_format', data_format)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 这是我自己添加的第二个模型及其配置文件，模型的具体细节可以在 /home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFFNetwork.py 这个目录里看到\r\n",
    "# 简要介绍一下模型、损失函数、数据增强、学习率和训练策略以及出现的一些问题\r\n",
    "# 模型：我们采用FCN架构，以paddlecls中提供的res2net200以及其预训练权重做为骨干网络来提取特征信息，输入数据为3×256×256的图片，四层layer我们分别提取了256×64×64、 512×32×32 、 1024×16×16、 2048×8×8的特征信息\r\n",
    "     # 本次比赛的要求是生成具有目标的单通道图，一般的做法为四层特征信息的融合，即encoder-decoder架构，我们也是采用这样的方法，只不过在中间添加了特征优化的模块，可见 ACFFNetwork.py中的自优化模块（SR），注意力模块（SE）等，\r\n",
    "     # 关于这些模块我将会在另外的方案分享里具体描述，本次提交就不做过细讲解.四层特征经过融合后使用3×3卷积调整为1通道，经过sigmoid函数与上采样恢复到原尺寸输出后在loss函数（一会细讲）和Momentum优化器的优化下进行训练.\r\n",
    "# 损失函数：我们自己实现了iou损失函数在2分类中的实现 代码见：external-libraries/paddle_seg_semi1/paddleseg/models/losses/semi_loss.py\r\n",
    "# 数据增强：根据paddleseg的用法，我们并没有用过多的数据增强操作，只用了resize、 对比度亮度、水平翻转、垂直反转、随即模糊、归一化这些操作，训练数据使用随机种子固定随机数，随机选取2K个作为验证集.\r\n",
    "# 学习率：使用paddleseg推荐的poly decay 作为学习率衰减策略，初始学习率为0.01，最小学习率为0.0001，\r\n",
    "# 训练策略以及一些问题：训练策略如下，3000次迭代保存一次模型，本来打算训练2w4k次迭代，但是发现模型在1w2k次迭代效果最好，但是loss和评价指标却一直在变好，可能是存在验证集过拟合的现象，具体原因不知.\r\n",
    "\r\n",
    "# 这是训练代码，复现请配置好文件后直接运行下一个代码块 如果要训练 就取消14-20行的注释\r\n",
    "\r\n",
    "\r\n",
    "# %cd external-libraries/paddle_seg_semi1/\r\n",
    "# !python train.py --config configs/semi/fcn_ACFFNet_semi_50k.yml \\\r\n",
    "# --do_eval \\\r\n",
    "# --save_dir /home/aistudio/output/acff \\\r\n",
    "# --save_interval 3000 \\\r\n",
    "# --log_iters 100  \\\r\n",
    "# --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这是预测的代码，依然是根据paddleseg套件直接运行的，采取了多尺度预测和水平翻转的预测策略， 这里就没什么好讲的了\r\n",
    "# 要复现结果，则必须运行这块代码\r\n",
    "%cd external-libraries/paddle_seg_semi1/\r\n",
    "!python predict.py --config configs/semi/fcn_ACFFNet_semi_50k.yml \\\r\n",
    "--model_path /home/aistudio/data/data99666/res2net200_score_0.80918.pdparams \\\r\n",
    "--image_path /home/aistudio/data/test_image/ \\\r\n",
    "--save_dir /home/aistudio/output/result_acff \\\r\n",
    "--aug_pred --scales  1 1.5 2 \\\r\n",
    "--flip_horizontal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## ACFF ViT ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'external-libraries/paddle_seg_semi1/'\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1\n",
      "/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "2021-08-02 07:47:43 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 这是我自己添加的第三个模型及其配置文件，模型的具体细节可以在 /home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py 这个目录里看到\r\n",
    "# 简要介绍一下模型、损失函数、数据增强、学习率和训练策略以及出现的一些问题\r\n",
    "# 模型：我们采用FCN架构，以paddlecls中提供的SwinTrasnformer以及其预训练权重做为骨干网络来提取特征信息，输入数据为3×384×384的图片，四层layer我们分别提取了不同大小不同通道数的四层特征信息\r\n",
    "     # 本次比赛的要求是生成具有目标的单通道图，一般的做法为四层特征信息的融合，即encoder-decoder架构，我们也是采用这样的方法，只不过在中间添加了特征优化的模块，可见 ACFF_ViT.py中的自优化模块（SR），注意力模块（SE）等，\r\n",
    "     # 关于这些模块我将会在另外的方案分享里具体描述，本次提交就不做过细讲解.四层特征经过融合后使用3×3卷积调整为1通道，经过sigmoid函数与上采样恢复到原尺寸输出后在loss函数（一会细讲）和Momentum优化器的优化下进行训练.\r\n",
    "# 损失函数：我们自己实现了iou损失函数在2分类中的实现 代码见：external-libraries/paddle_seg_semi1/paddleseg/models/losses/semi_loss.py\r\n",
    "# 数据增强：根据paddleseg的用法，我们并没有用过多的数据增强操作，只用了resize、 对比度亮度、水平翻转、垂直反转、随即模糊、归一化这些操作，训练数据使用随机种子固定随机数，随机选取2K个作为验证集.\r\n",
    "# 学习率：使用paddleseg推荐的poly decay 作为学习率衰减策略，初始学习率为0.01，最小学习率为0.0001，\r\n",
    "# 训练策略以及一些问题：训练策略如下，bs = 4, 4000次迭代保存一次模型，训练2个epoch后效果最好\r\n",
    "\r\n",
    "# 这是训练代码，复现请配置好文件后直接运行下一个代码块 如果要训练 就取消14-20行的注释\r\n",
    "\r\n",
    "\r\n",
    "# %cd external-libraries/paddle_seg_semi1/\r\n",
    "# !python train.py --config configs/semi/fcn_ACFFViT.yml \\\r\n",
    "# --do_eval \\\r\n",
    "# --save_dir /home/aistudio/output/vit \\\r\n",
    "# --save_interval 4000 \\\r\n",
    "# --log_iters 100  \\\r\n",
    "# --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这是预测的代码，依然是根据paddleseg套件直接运行的，采取了水平翻转的预测策略， 因为transformer固定大小的输入模式，只能固定384尺寸输入 所以没有采用多尺度预测\r\n",
    "# 要复现结果，则必须运行这块代码\r\n",
    "%cd external-libraries/paddle_seg_semi1/\r\n",
    "!python predict.py --config configs/semi/fcn_ACFFViT.yml \\\r\n",
    "--model_path /home/aistudio/data/data99666/ACFFViT4.pdparams\\\r\n",
    "--image_path /home/aistudio/data/test_image \\\r\n",
    "--save_dir /home/aistudio/output/result_vit \\\r\n",
    "--aug_pred \\\r\n",
    "--flip_horizontal\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############## Next_ACFF ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这是我自己添加的第四个模型及其配置文件，模型的具体细节可以在 /home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/Next_ACFF.py 这个目录里看到\r\n",
    "# 简要介绍一下模型、损失函数、数据增强、学习率和训练策略以及出现的一些问题\r\n",
    "# 模型：我们采用FCN架构，以paddlecls中提供的ResNeXt101WSL以及其预训练权重做为骨干网络来提取特征信息，输入数据为3×256×256的图片，四层layer我们分别提取了256×64×64、 512×32×32 、 1024×16×16、 2048×8×8的特征信息\r\n",
    "     # 本次比赛的要求是生成具有目标的单通道图，一般的做法为四层特征信息的融合，即encoder-decoder架构，我们也是采用这样的方法，只不过在中间添加了特征优化的模块，可见 Next_ACFF.py中的自优化模块（SR），注意力模块（SE）等，\r\n",
    "     # 关于这些模块我将会在另外的方案分享里具体描述，本次提交就不做过细讲解.四层特征经过融合后使用3×3卷积调整为1通道，经过sigmoid函数与上采样恢复到原尺寸输出后在loss函数（一会细讲）和Momentum优化器的优化下进行训练.\r\n",
    "# 损失函数：我们自己实现了iou损失函数在2分类中的实现 代码见：external-libraries/paddle_seg_semi1/paddleseg/models/losses/semi_loss.py\r\n",
    "# 数据增强：根据paddleseg的用法，我们并没有用过多的数据增强操作，只用了resize、 对比度亮度、水平翻转、垂直反转、随即模糊、归一化这些操作，训练数据使用随机种子固定随机数，随机选取2K个作为验证集.\r\n",
    "# 学习率：使用paddleseg推荐的poly decay 作为学习率衰减策略，初始学习率为0.01，最小学习率为0.0001，\r\n",
    "# 训练策略以及一些问题：训练策略如下，2000次迭代保存一次模型，多少次迭代效果最好已经忘了，肯定不是最后一次，还是中间某次\r\n",
    "\r\n",
    "# 这是训练代码，复现请配置好文件后直接运行下一个代码块 如果要训练 就取消14-20行的注释\r\n",
    "\r\n",
    "\r\n",
    "# %cd external-libraries/paddle_seg_semi1/\r\n",
    "# !python train.py --config configs/semi/fcn_NextACFF.yml \\\r\n",
    "# --do_eval \\\r\n",
    "# --save_dir /home/aistudio/output/next \\\r\n",
    "# --save_interval 2000 \\\r\n",
    "# --log_iters 100  \\\r\n",
    "# --use_vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这是预测的代码，依然是根据paddleseg套件直接运行的，采取了多尺度预测和水平翻转的预测策略， 这里就没什么好讲的了\r\n",
    "# 要复现结果，则必须运行这块代码\r\n",
    "%cd external-libraries/paddle_seg_semi1/\r\n",
    "!python predict.py --config configs/semi/fcn_NextACFF.yml \\\r\n",
    "--model_path /home/aistudio/data/data99666/NextACFF.pdparams \\\r\n",
    "--image_path /home/aistudio/data/test_image/ \\\r\n",
    "--save_dir /home/aistudio/output/result_acffnext \\\r\n",
    "--aug_pred --scales  1 1.5 2 \\\r\n",
    "--flip_horizontal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 另外说一下，我们根据比赛的评价指标，修改了 external-libraries/paddle_seg_semi1/paddleseg/core/train.py、 infer.py、 predict.py、 val.py等文件\r\n",
    "# 但不影响运行，主要修改为：更改了评价指标 修改了输入输出的数据类型 int -> float32   修改了输出 多保存了图像的npy文件用于后续的模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aistudio/external-libraries/paddle_seg_semi1/paddleseg/models/ACFF_ViT.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "10985/10989 [============================>.] - ETA: 0"
     ]
    }
   ],
   "source": [
    "# 这个融合策略是上述四个模型结果取平均融合的方法，B榜结果8.0383 不是最好的结果  可以忽略， 只是我不想删，因为是我队友辛苦写出来的\r\n",
    "\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import glob\r\n",
    "\r\n",
    "from paddleseg.utils import logger, progbar\r\n",
    "\r\n",
    "save_image_path = '/home/aistudio/output/result_ensem/pre'\r\n",
    "if not os.path.exists(save_image_path):\r\n",
    "    os.makedirs(save_image_path)\r\n",
    "\r\n",
    "logits_path = [\r\n",
    "    '/home/aistudio/output/result_acff/logits',\r\n",
    "    '/home/aistudio/output/result_fmf/logits',\r\n",
    "    '/home/aistudio/output/result_vit/logits',\r\n",
    "    '/home/aistudio/output/result_acffnext/logits'\r\n",
    "]\r\n",
    "npy_list = glob.glob(os.path.join(logits_path[0], '*.npy'))\r\n",
    "npy_list = [npy.split('/')[-1] for npy in npy_list]\r\n",
    "\r\n",
    "progbar_pred = progbar.Progbar(target=len(npy_list), verbose=1)\r\n",
    "\r\n",
    "weights = [0.2, 0.2, 0.2, 0.4]\r\n",
    "\r\n",
    "for j, npy in enumerate(npy_list):\r\n",
    "    final_logit = 0\r\n",
    "    for i, path in enumerate(logits_path):\r\n",
    "        if 'vit' in path:\r\n",
    "            logit = np.load(os.path.join(path, npy)) / 2.0\r\n",
    "        else:\r\n",
    "            logit = np.load(os.path.join(path, npy)) / 6.0\r\n",
    "        final_logit += logit\r\n",
    "\r\n",
    "    final_logit = final_logit / len(logits_path)\r\n",
    "    pre = final_logit#[:, 1, :, :]\r\n",
    "    pre = pre[0,:,:]\r\n",
    "    pre = np.transpose(pre, [1, 2, 0]).squeeze(axis=-1) * 255\r\n",
    "    \r\n",
    "    cv2.imwrite(os.path.join(save_image_path, npy.split('.')[0] + '.jpg'), pre)\r\n",
    "    progbar_pred.update(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10989"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\r\n",
    "len(os.listdir('/home/aistudio/output/result_ensem/pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这个融合策略是上述四个模型结果加权融合的方法，B榜最好结果8.0428 达到最好的结果 \r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import glob\r\n",
    "\r\n",
    "from paddleseg.utils import logger, progbar\r\n",
    "\r\n",
    "save_image_path = '/home/aistudio/output/result_ensem_weight/pre'\r\n",
    "if not os.path.exists(save_image_path):\r\n",
    "    os.makedirs(save_image_path)\r\n",
    "\r\n",
    "logits_path = [\r\n",
    "    '/home/aistudio/output/result_acff/logits',\r\n",
    "    '/home/aistudio/output/result_fmf/logits',\r\n",
    "    '/home/aistudio/output/result_vit/logits',\r\n",
    "    '/home/aistudio/output/result_acffnext/logits'\r\n",
    "] # 这是上述四个模型产生的图像npy文件\r\n",
    "\r\n",
    "\r\n",
    "npy_list = glob.glob(os.path.join(logits_path[0], '*.npy'))\r\n",
    "npy_list = [npy.split('/')[-1] for npy in npy_list]\r\n",
    "\r\n",
    "progbar_pred = progbar.Progbar(target=len(npy_list), verbose=1) # paddleseg自带的进度条\r\n",
    "\r\n",
    "weights = [0.4, 0.2, 0.2, 0.2] # 四个npy文件的权重\r\n",
    "\r\n",
    "for j, npy in enumerate(npy_list):\r\n",
    "    final_logit = 0\r\n",
    "    for i, path in enumerate(logits_path):\r\n",
    "        if 'vit' in path:\r\n",
    "            logit = np.load(os.path.join(path, npy)) / 2.0  # 这是transformer为骨干网络预测的结果 /2.0是因为加了水平翻转预测\r\n",
    "        else:\r\n",
    "            logit = np.load(os.path.join(path, npy)) / 6.0 # 这是其他三个模型预测的结果 /6.0是因为加了水平翻转预测 以及三个尺度预测 即2*3 = 6\r\n",
    "        final_logit = final_logit +  logit * weights[i] # 加权融合\r\n",
    "\r\n",
    "  #  final_logit = final_logit / len(logits_path)\r\n",
    "    pre = final_logit#[:, 1, :, :]\r\n",
    "    pre = pre[0,:,:]\r\n",
    "    pre = np.transpose(pre, [1, 2, 0]).squeeze(axis=-1) * 255\r\n",
    "    \r\n",
    "    cv2.imwrite(os.path.join(save_image_path, npy.split('.')[0] + '.jpg'), pre) # 输出\r\n",
    "    progbar_pred.update(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 第一次  [0.4, 0.2, 0.2, 0.2] finished 结果记录 可忽略\r\n",
    "# 第二次 [0.2, 0.4, 0.2, 0.2] finished\r\n",
    "# 第三次 [0.2, 0.2, 0.4, 0.2] finished\r\n",
    "# 第四次 [0.2, 0.2, 0.2, 0.4] finished\r\n",
    "# 第五次 [0.5, 0.2, 0.15, 0.15] finished\r\n",
    "# 第六次 [0.6, 0.2, 0.1, 0.1] finished\r\n",
    "# 第七次 [0.5, 0.3, 0.1, 0.1] finished\r\n",
    "# 第八次 weights = [0.5, 0.1, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 提升思路\n",
    "<font size=3 >1. 采用学习率预热+学习率余弦衰减的策略，主要是使用套件不方便手动实现lr衰减策略，所以我们就用自带的poly decay策略\n",
    "  \n",
    "2. 采用更好的损失函数，如加权iou，参考显著目标检测顶会F3Net 和MINet这两篇文章提出的损失函数。\n",
    "  \n",
    "3. 给模型增加更多有用的模块（较难）\n",
    "\n",
    "4. 多尺度训练，即使用dataloader中collate参数，编写函数将输入的一个batch的数据 随机resize到[22,256,288,320,356,384]进行训练。\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 致谢\n",
    "<font size=3 >最后感谢我的队友以及paddle的部分官方人员，包括GT哥，生而为~~弟~~帝等等，paddle是我通过这次比赛才接触到的深度学习框架，\n",
    "并且在不断的学习和使用过程中也加深了对paddle的了解，paddle大量的套件是我之前学习的深度学习框架所不具有的，从其他框架转移到paddle也可以毫不费力。\n",
    "  总之，paddle带给了我更多的惊喜，以后我也会继续为paddle贡献自己的代码。\n",
    " \n",
    "  **方案分享完毕，谢谢大家的观看！！！**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
